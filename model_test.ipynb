{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import make_tensor\n",
    "\n",
    "from model import InputEmbedding\n",
    "\n",
    "d_model = 12\n",
    "vocab_size = 3\n",
    "batch_size = 3\n",
    "seq_len = 5\n",
    "# since this is the tensor for embedding, we need to use int type\n",
    "t = make_tensor((batch_size,seq_len), device='cpu', dtype=torch.int, low=0, high=vocab_size-1)\n",
    "\n",
    "input_embedding = InputEmbedding(d_model, vocab_size)\n",
    "ret = input_embedding(t)\n",
    "assert ret.shape == (batch_size, seq_len, d_model)\n",
    "assert ret.dtype == torch.float\n",
    "assert ret.device.type == \"cpu\", f\"device {ret.device}\"\n",
    "# torch.testing.assert_close(ret, expected, check_layout=True, check_device=True, check_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 1.0000],\n",
      "         [0.8415, 0.5403]]])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00],\n",
      "         [-2.9027e-05,  2.3246e-06]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.testing import make_tensor\n",
    "\n",
    "from model import PositionEmbedding\n",
    "\n",
    "batch_size = 1\n",
    "d_model = 2\n",
    "max_seq_len = 5\n",
    "seq_len = 2\n",
    "dropout = 0\n",
    "pe = PositionEmbedding(d_model, max_seq_len, dropout)\n",
    "\n",
    "t = make_tensor((batch_size, seq_len, d_model), device='cpu', dtype=torch.float32, low=-1, high=1)\n",
    "ret = pe(t)\n",
    "expected_diff = torch.tensor([[[0.0000, 1.0000], [0.8415, 0.5403]]], dtype=torch.float32)\n",
    "torch.testing.assert_close(ret-t, expected_diff, rtol=0.001, atol=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import LayerNormalization\n",
    "\n",
    "ln = LayerNormalization()\n",
    "t = torch.tensor([[1.0, 3.0], [2.0, 4.0]], dtype=torch.float32)\n",
    "ret = ln(t)\n",
    "torch.testing.assert_close(ret, \n",
    "    torch.tensor([[-0.7071, 0.7071], [-0.7071, 0.7071]]), \n",
    "    rtol=0.001, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import FeedForwardLayer\n",
    "\n",
    "d_model= 2\n",
    "d_ff=4\n",
    "ff = FeedForwardLayer(d_model, d_ff, 0.0)\n",
    "t = torch.tensor([[1.0, 3.0], [2.0, 4.0]], dtype=torch.float32)\n",
    "ret = ff(t)\n",
    "assert ret.shape == t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.2721,  0.8713, -0.5806, -3.0091,  1.2611,  2.9500],\n",
      "         [-2.3816,  1.1305, -0.7528, -2.9254,  1.1528,  2.8034]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import MultiHeadAttentionBlock\n",
    "\n",
    "d_model = 6\n",
    "n_heads = 2\n",
    "mh = MultiHeadAttentionBlock(d_model, n_heads, 0.0)\n",
    "# (batch:1, seq:2, d_model:6)\n",
    "t = torch.tensor([[1.0, 3.0, 5.0, 7.0, 9.0, 11.0], [2.0, 4.0, 6.0, 8.0, 10.0, 12.0]], dtype=torch.float32)\n",
    "t = t.unsqueeze(0)\n",
    "mask = torch.tensor([[1, 0], [1,1]], dtype=torch.float32)\n",
    "ret = mh(t, mask)\n",
    "print(ret)\n",
    "assert ret.shape == t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4823, 1.7688],\n",
      "        [1.4823, 2.7688]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import ResidualConnection\n",
    "\n",
    "sublayer = nn.Linear(2, 2)\n",
    "rc = ResidualConnection(0.0)\n",
    "# (batch:1, seq:2, d_model:2)\n",
    "t = torch.tensor([[1.0, 3.0,], [2.0, 4.0]], dtype=torch.float32)\n",
    "ret = rc(t, sublayer)\n",
    "print(ret)\n",
    "assert ret.shape == t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4823, 1.7688],\n",
      "        [1.4823, 2.7688]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import EncoderBlock\n",
    "\n",
    "rc = ResidualConnection(0.0)\n",
    "# (batch:1, seq:2, d_model:2)\n",
    "t = torch.tensor([[1.0, 3.0,], [2.0, 4.0]], dtype=torch.float32)\n",
    "ret = rc(t, sublayer)\n",
    "print(ret)\n",
    "assert ret.shape == t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
