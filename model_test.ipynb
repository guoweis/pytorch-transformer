{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-14.1.2-arm64-arm-64bit\n",
      "PyTorch Version: 2.1.2\n",
      "\n",
      "Python 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:35:41) \n",
      "[Clang 16.0.6 ]\n",
      "Pandas 2.1.4\n",
      "Scikit-Learn 1.3.2\n",
      "NVIDIA/CUDA GPU is NOT AVAILABLE\n",
      "MPS (Apple Metal) is AVAILABLE\n",
      "Target device is mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/39xmrqvj4c35fzml_g44x6lc0000gq/T/ipykernel_78671/3769477546.py:9: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  has_mps = getattr(torch,'has_mps',False)\n",
      "/var/folders/qw/39xmrqvj4c35fzml_g44x6lc0000gq/T/ipykernel_78671/3769477546.py:10: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = \"mps\" if getattr(torch,'has_mps',False) \\\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = getattr(torch,'has_mps',False)\n",
    "device = \"mps\" if getattr(torch,'has_mps',False) \\\n",
    "    else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"NVIDIA/CUDA GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import make_tensor\n",
    "\n",
    "from model import InputEmbedding\n",
    "\n",
    "d_model = 12\n",
    "vocab_size = 3\n",
    "batch_size = 3\n",
    "seq_len = 5\n",
    "# since this is the tensor for embedding, we need to use int type\n",
    "t = make_tensor((batch_size,seq_len), device=device, dtype=torch.int, low=0, high=vocab_size-1)\n",
    "\n",
    "input_embedding = InputEmbedding(d_model, vocab_size).to(device)\n",
    "ret = input_embedding(t)\n",
    "assert ret.shape == (batch_size, seq_len, d_model)\n",
    "assert ret.dtype == torch.float\n",
    "assert ret.device.type == device, f\"device {ret.device}\"\n",
    "# torch.testing.assert_close(ret, expected, check_layout=True, check_device=True, check_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import make_tensor\n",
    "\n",
    "from model import PositionEmbedding\n",
    "\n",
    "batch_size = 1\n",
    "d_model = 2\n",
    "max_seq_len = 5\n",
    "seq_len = 2\n",
    "dropout = 0\n",
    "pe = PositionEmbedding(d_model, max_seq_len, dropout).to(device)\n",
    "\n",
    "t = make_tensor((batch_size, seq_len, d_model), device=device, dtype=torch.float32, low=-1, high=1)\n",
    "ret = pe(t)\n",
    "expected_diff = torch.tensor([[[0.0000, 1.0000], [0.8415, 0.5403]]], dtype=torch.float32, device=device)\n",
    "torch.testing.assert_close(ret-t, expected_diff, rtol=0.001, atol=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import LayerNormalization\n",
    "\n",
    "ln = LayerNormalization().to(device)\n",
    "t = torch.tensor([[1.0, 3.0], [2.0, 4.0]], dtype=torch.float32, device=device)\n",
    "ret = ln(t)\n",
    "torch.testing.assert_close(ret, \n",
    "    torch.tensor([[-0.7071, 0.7071], [-0.7071, 0.7071]], device=device), \n",
    "    rtol=0.001, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import FeedForwardLayer\n",
    "\n",
    "d_model= 2\n",
    "d_ff=4\n",
    "ff = FeedForwardLayer(d_model, d_ff, 0.0).to(device)\n",
    "t = torch.tensor([[1.0, 3.0], [2.0, 4.0]], dtype=torch.float32, device=device)\n",
    "ret = ff(t)\n",
    "assert ret.shape == t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4387,  1.0943,  1.6182, -0.1563,  0.9320, -0.1748],\n",
      "         [-0.4572,  1.1914,  1.6225, -0.1268,  0.9637, -0.2005]]],\n",
      "       device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import MultiHeadAttentionBlock\n",
    "\n",
    "d_model = 6\n",
    "n_heads = 2\n",
    "mh = MultiHeadAttentionBlock(d_model, n_heads, 0.0).to(device)\n",
    "# (batch:1, seq:2, d_model:6)\n",
    "t = torch.tensor([[1.0, 3.0, 5.0, 7.0, 9.0, 11.0], [2.0, 4.0, 6.0, 8.0, 10.0, 12.0]], dtype=torch.float32, device=device)\n",
    "t = t.unsqueeze(0)\n",
    "mask = torch.tensor([[1, 0], [1,1]], dtype=torch.float32, device=device)\n",
    "ret = mh(t, t, t, mask)\n",
    "print(ret)\n",
    "assert ret.shape == t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3933, 2.2991],\n",
      "        [2.3933, 3.2991]], device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import ResidualConnection\n",
    "\n",
    "sublayer = nn.Linear(2, 2).to(device)\n",
    "rc = ResidualConnection(0.0).to(device)\n",
    "# (batch:1, seq:2, d_model:2)\n",
    "t = torch.tensor([[1.0, 3.0,], [2.0, 4.0]], dtype=torch.float32, device=device)\n",
    "ret = rc(t, sublayer)\n",
    "print(ret)\n",
    "assert ret.shape == t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.1108, 1.5394],\n",
      "         [2.1108, 2.5394]]], device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import EncoderBlock, MultiHeadAttentionBlock, FeedForwardLayer\n",
    "\n",
    "d_model = 2\n",
    "n_heads = 2\n",
    "d_ff = 4\n",
    "dropout = 0.0\n",
    "mh = MultiHeadAttentionBlock(d_model, n_heads, dropout).to(device)\n",
    "ff = FeedForwardLayer(d_model, d_ff, dropout).to(device)\n",
    "\n",
    "eb = EncoderBlock(mh, ff, dropout).to(device)\n",
    "# (batch:1, seq:2, d_model:2)\n",
    "t = torch.tensor([[1.0, 3.0,], [2.0, 4.0]], dtype=torch.float32, device=device)\n",
    "t = t.unsqueeze(0)\n",
    "mask = torch.tensor([[1, 0], [1,1]], dtype=torch.float32, device=device)\n",
    "\n",
    "ret = eb(t, mask)\n",
    "print(ret)\n",
    "assert ret.shape == t.shape, f\"ret.shape: {ret.shape} vs t.shape: {t.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.2758, 4.4797],\n",
      "         [4.4520, 5.5926]]], device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import DecoderBlock, MultiHeadAttentionBlock, FeedForwardLayer\n",
    "\n",
    "d_model = 2\n",
    "n_heads = 2\n",
    "d_ff = 4\n",
    "dropout = 0.0\n",
    "mh = MultiHeadAttentionBlock(d_model, n_heads, dropout).to(device)\n",
    "mh2 = MultiHeadAttentionBlock(d_model, n_heads, dropout).to(device)\n",
    "\n",
    "ff = FeedForwardLayer(d_model, d_ff, dropout).to(device)\n",
    "\n",
    "db = DecoderBlock(mh, mh2, ff, dropout).to(device)\n",
    "# (batch:1, seq:2, d_model:2)\n",
    "t = torch.tensor([[1.0, 3.0,], [2.0, 4.0]], dtype=torch.float32, device=device)\n",
    "t = t.unsqueeze(0)\n",
    "mask = torch.tensor([[1, 0], [1,1]], dtype=torch.float32, device=device)\n",
    "ret = db(t, t, mask, mask)\n",
    "print(ret)\n",
    "assert ret.shape == t.shape, f\"ret.shape: {ret.shape} vs t.shape: {t.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9028, -1.8150, -2.0259, -1.2044],\n",
      "        [-0.5085, -2.2451, -2.7488, -1.4754]], device='mps:0',\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import ProjectionLayer\n",
    "\n",
    "d_model = 2\n",
    "vocab_size = 4\n",
    "pj = ProjectionLayer(d_model, vocab_size).to(device)\n",
    "t = torch.tensor([[1.0, 3.0,], [2.0, 4.0]], dtype=torch.float32, device=device)\n",
    "ret = pj(t)\n",
    "print(ret)\n",
    "assert ret.shape == ( 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x EncoderBlock(\n",
      "        (self_attention): MultiHeadAttentionBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual1): ResidualConnection(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (norm): LayerNormalization()\n",
      "        )\n",
      "        (residual2): ResidualConnection(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (norm): LayerNormalization()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNormalization()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x DecoderBlock(\n",
      "        (self_attention): MultiHeadAttentionBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (cross_attention): MultiHeadAttentionBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual1): ResidualConnection(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (norm): LayerNormalization()\n",
      "        )\n",
      "        (residual2): ResidualConnection(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (norm): LayerNormalization()\n",
      "        )\n",
      "        (residual3): ResidualConnection(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (norm): LayerNormalization()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNormalization()\n",
      "  )\n",
      "  (src_embed): InputEmbedding(\n",
      "    (embedding): Embedding(2, 512)\n",
      "  )\n",
      "  (src_pos): PositionEmbedding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (tgt_embed): InputEmbedding(\n",
      "    (embedding): Embedding(2, 512)\n",
      "  )\n",
      "  (tgt_pos): PositionEmbedding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (projection): ProjectionLayer(\n",
      "    (linear): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import build_transformer\n",
    "\n",
    "transformer = build_transformer(2, 2, 2, 2).to(device)\n",
    "print(transformer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
